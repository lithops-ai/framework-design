{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lithops Design Docs","text":"<p>This is the design documentation for the Lithops Multi-Agent Framework.</p>"},{"location":"communication-mechanism-design/","title":"Lithops - Communication Mechanism Design","text":""},{"location":"communication-mechanism-design/#1-goals-and-background","title":"1. Goals and Background","text":"<ol> <li>In large-scale distributed applications, it is necessary to provide a \"real-time communication + topic/subtopic\" based collaborative model for millions of dispersed Agents (deployed across cloud, edge, IoT devices, etc.).</li> <li>The goal is to enable Agents to interact hierarchically through a \"Discord-like\" user experience, structured around \u201cChannel-Thread-Message,\u201d while supporting access control, group management, attachment handling, message history tracking, and other features.</li> <li>Within cloud-native ecosystems, the solution should leverage Kubernetes CRD + Operator to achieve declarative configuration and fully automated operations. However, it must avoid mapping millions of Agent identities or messages directly onto etcd to minimize overloading the Kubernetes control plane.</li> </ol>"},{"location":"communication-mechanism-design/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>To ensure high concurrency and scalability, the system is divided into the following core components:</p> <ol> <li> <p>Kubernetes API Server / etcd</p> <ul> <li>Only stores essential metadata such as \"Channels/Threads\" (as CRDs) and small summaries like \"Groups\" or access control information.</li> <li>Does not store millions of Agent identities or message histories.</li> </ul> </li> <li> <p>Message Queue System (MQ)</p> <ul> <li>Systems like NATS, RabbitMQ, Kafka, etc., are used to handle large-scale, real-time, high-throughput message distribution.</li> <li>Each Channel or Thread corresponds to a Subject/Topic/Queue in the MQ system, enabling isolation similar to \"Discord Channels-Threads.\"</li> </ul> </li> <li> <p>CollaborationPolicyService (External Identity + Access Control Management)</p> <ul> <li>An independent service that manages Agent identities (IDs), Groups, and Role information, as well as access control policies for collaboration scenarios.</li> <li>Operators and the MQ system consult this service to verify Agent permissions for Channels/Threads; simultaneously, Agent clients must authenticate through this service before connecting.</li> </ul> </li> <li> <p>Channel/Thread Operator</p> <ul> <li>Monitors Channel and Thread CRDs defined in Kubernetes, automating the creation and update of their corresponding topics/routing policies in the MQ system.</li> <li>Interacts with CollaborationPolicyService to grant/revoke group access to Channels/Threads without creating a large number of RoleBindings in Kubernetes.</li> </ul> </li> <li> <p>Agents (Millions of Instances)</p> <ul> <li>Deployed on cloud or edge nodes, these connect to the MQ system via SDKs or APIs to publish and subscribe to messages, enabling collaborative interaction.</li> <li>Before connecting, Agents authenticate with the CollaborationPolicyService to receive certificates or tokens, enabling their access to specific Channels/Threads.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#3-key-requirements-and-challenges","title":"3. Key Requirements and Challenges","text":"<ol> <li> <p>Massive Scale &amp; Multi-Agent Concurrency</p> <ul> <li>Millions of Agents need to communicate simultaneously, publishing/subscribing to messages with high-speed. Traditional monolithic systems are inadequate for this scale.</li> </ul> </li> <li> <p>Hierarchical Access Control</p> <ul> <li>Different Agents possess different roles (e.g., Owner, Moderator, Member), but each Agent's role cannot be mapped into Kubernetes RoleBindings. Access control must be externalized.</li> </ul> </li> <li> <p>Real-Time Messaging and History</p> <ul> <li>Similar to a \u201cDiscord-like\u201d system, the platform must deliver low-latency message distribution while supporting searchable and replayable message history in Channels/Threads.</li> </ul> </li> <li> <p>Cloud-Native Scalability</p> <ul> <li>The system should seamlessly scale within Kubernetes, leveraging Operators for fully automated operations, minimizing the need for manual management of message middleware configurations.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#4-logical-layer-design","title":"4. Logical Layer Design","text":""},{"location":"communication-mechanism-design/#41-core-concepts","title":"4.1 Core Concepts","text":"<ol> <li> <p>Channel</p> <ul> <li>Represents a discussion space for a group, topic, or major task, which can be public or private.</li> <li>Configurable attributes include visibility (public/private), read/write policies, persistence options, etc.</li> <li>Most Agents do not directly interact with Kubernetes; instead, they depend on the CollaborationPolicyService to determine whether they can \u201cjoin\u201d a given Channel.</li> </ul> </li> <li> <p>Thread</p> <ul> <li>A sub-discussion space within a Channel, inheriting or defining separate access permissions.</li> <li>Helps segregate and focus discussions to avoid overwhelming the main Channel.</li> </ul> </li> <li> <p>Message</p> <ul> <li>The core communication unit containing text, attachments, mentions, etc.</li> <li>Messaging payloads are not recommended for storage in etcd. Instead, MQ or external databases should handle them for real-time processing and historical storage.</li> </ul> </li> <li> <p>Mentions</p> <ul> <li>For example, \u201c@AgentX\u201d or \u201c@Group,\u201d enabling priority notifications or targeted pushing via MQ.</li> <li>CollaborationPolicyService resolves aliases into actual Agent IDs.</li> </ul> </li> <li> <p>Roles</p> <ul> <li>Owner: Manages Channel configurations, adds/removes groups.</li> <li>Moderator: Can administratively block specific groups or Agents (maintained through the CollaborationPolicyService).</li> <li>Member: Regular participants sending/receiving messages in Channels.</li> <li>Roles are handled exclusively in CollaborationPolicyService\u2014not within Kubernetes itself.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#5-implementation-details","title":"5. Implementation Details","text":""},{"location":"communication-mechanism-design/#51-simplified-crd-design","title":"5.1 Simplified CRD Design","text":""},{"location":"communication-mechanism-design/#511-channel-crd","title":"5.1.1 Channel CRD","text":"<p>Instead of maintaining RoleBinding for every individual Agent, it only contains minimal group-based metadata.</p> <pre><code>apiVersion: agents.platform.io/v1\nkind: Channel\nmetadata:\n  name: sensor-anomaly-channel\nspec:\n  visibility: \"private\"  # Other values: \"public\"\n  authorizedGroups:\n    - \"EdgeSensorsGroup\"\n    - \"MLWorkersGroup\"\n  enablePersistence: true    # Enables historical storage in MQ\n  retentionPolicy: \"7d\"      # Operator parses this field\nstatus:\n  natsSubject: \"channels.sensors.anomaly\"\n  state: \"Active\"\n</code></pre>"},{"location":"communication-mechanism-design/#512-thread-crd","title":"5.1.2 Thread CRD","text":"<pre><code>apiVersion: agents.platform.io/v1\nkind: Thread\nmetadata:\n  name: anomaly-subanalysis\nspec:\n  channel: \"sensor-anomaly-channel\"\n  participantsGroups:\n    - \"AnomalyFocusedGroup\"  # Can inherit from parent Channel or define separately\n  topic: \"Sensor anomalies sub-thread\"\nstatus:\n  natsSubject: \"channels.sensors.anomaly.thread-xyz\"\n  state: \"Ongoing\"\n</code></pre>"},{"location":"communication-mechanism-design/#52-operators","title":"5.2 Operators","text":""},{"location":"communication-mechanism-design/#521-channel-operator","title":"5.2.1 Channel Operator","text":"<ol> <li>Monitoring Channel CRDs for Create/Update/Delete operations.</li> <li> <p>On detecting a new Channel:</p> <ul> <li>Use MQ APIs (e.g., NATS Admin) to create a corresponding topic (Subject/Topic/Queue).</li> <li>Update the authorization policies in CollaborationPolicyService for designated <code>authorizedGroups</code>.</li> <li>Adhere to <code>enablePersistence</code> and <code>retentionPolicy</code> to configure MQ persistence policies.</li> </ul> </li> <li> <p>On Channel Updates:</p> <ul> <li>Adjust CollaborationPolicyService permissions if <code>authorizedGroups</code> are modified.</li> <li>Update MQ persistence policies if <code>enablePersistence</code> or <code>retentionPolicy</code> changes.</li> </ul> </li> <li> <p>On Channel Deletion:</p> <ul> <li>Mark the MQ topic for archival or cleanup. Physically delete the topic after a delay (optional).</li> <li>Revoke associated authorizations in CollaborationPolicyService.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#522-thread-operator","title":"5.2.2 Thread Operator","text":"<ol> <li>Monitoring Thread CRDs for CRUD events.</li> <li> <p>Logic mirrors that of the Channel Operator:</p> <ul> <li>Create sub-topics in MQ for Threads.</li> <li>Update permitted <code>participantsGroups</code> or inherit them from the parent Channel.</li> </ul> </li> <li> <p>When Threads are archived or deleted:</p> <ul> <li>Remove related sub-topics from the MQ and adjust retention policies accordingly.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#53-collaborationpolicyservice","title":"5.3 CollaborationPolicyService","text":"<ul> <li>An independent external or microservice-based system that leverages specialized databases (Postgres, Redis, NoSQL, etc.) to store identity, group, and role information for millions of Agents.</li> <li>Exposes APIs like <code>CheckPermission(AgentID, Subject)</code> and <code>UpdateChannelAuth(ChannelID, GroupList)</code> for use by Operators and MQ systems alike.</li> <li>Before an Agent attempts to join any Channel, it undergoes authentication and, upon success, receives an MQ access token allowing it to communicate securely.</li> </ul>"},{"location":"communication-mechanism-design/#54-mq-selection-and-configuration","title":"5.4 MQ Selection and Configuration","text":"<p>Let\u2019s take NATS as an example (alternatives include RabbitMQ or Kafka):</p> <ol> <li> <p>NATS on Kubernetes:</p> <ul> <li>Deploy NATS using a Kubernetes NATS Operator for automated scaling and failover.</li> </ul> </li> <li> <p>Subject Naming Convention:</p> <ul> <li>Tie Subjects to CRDs, e.g., <code>channels.&lt;channelName&gt;.threads.&lt;threadName&gt;</code>.</li> </ul> </li> <li> <p>JetStream Persistence:</p> <ul> <li>With persistence enabled, set up JetStream to manage histories via automatic Message Replay mechanisms.</li> </ul> </li> <li> <p>ACL and Security:</p> <ul> <li>Utilize NATS multi-tenant or Account-based ACL management. Allow group-specific tokens via CollaborationPolicyService, enabling secure logins.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#6-typical-messaging-workflow-example","title":"6. Typical Messaging Workflow Example","text":"<ol> <li> <p>Channel Creation:</p> <ul> <li>An Administrator submits a <code>Channel</code> CRD (\u201csensor-anomaly-channel\u201d), specifying <code>authorizedGroups = [\u201cEdgeSensorsGroup\u201d, \u201cMLWorkersGroup\u201d]</code>.</li> <li>The Channel Operator:<ul> <li>Creates a matching NATS Subject, \u201cchannels.sensors.anomaly.\u201d</li> <li>Updates CollaborationPolicyService to grant <code>EdgeSensorsGroup</code> and <code>MLWorkersGroup</code> access.</li> </ul> </li> </ul> </li> <li> <p>Agent Joins &amp; Sends Messages:</p> <ul> <li>AgentX (part of EdgeSensorsGroup) authenticates with CollaborationPolicyService and receives a token for \u201cchannels.sensors.anomaly.\u201d</li> <li>AgentX subscribes to the topic and pushes anomaly detection messages.</li> </ul> </li> <li> <p>Thread Creation:</p> <ul> <li>To deep-dive into details, a Thread CRD is created for a sub-topic (\u201canomaly-subanalysis\u201d).</li> <li>Thread Operator provisions the NATS sub-channel and updates permissions.</li> </ul> </li> <li> <p>Historical Replay:</p> <ul> <li>If JetStream persistence is enabled, Agents can replay historical messages, or archival tasks can operate seamlessly.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#7-advantages-and-value","title":"7. Advantages and Value","text":"<ol> <li> <p>Scalability:</p> <ul> <li>Offloads identity and message management to external systems, keeping etcd and Kubernetes Control Plane lightweight.</li> </ul> </li> <li> <p>Cloud-Native Integration:</p> <ul> <li>Stays declarative, leveraging Kubernetes Operators to seamlessly integrate with CRDs and external services.</li> </ul> </li> <li> <p>Flexibility:</p> <ul> <li>MQ (NATS, Kafka, etc.) and CollaborationPolicyService implementations are modular\u2014easy to swap or customize.</li> </ul> </li> <li> <p>Discord-like Experience:</p> <ul> <li>Fully supports Channels, Threads, Mentions, message searchability, and hierarchical permissions.</li> </ul> </li> <li> <p>Future Expansion:</p> <ul> <li>Extensible for advanced integrations, such as embedding LLMService Operators in the future.</li> </ul> </li> </ol>"},{"location":"communication-mechanism-design/#8-conclusion","title":"8. Conclusion","text":"<p>This design leverages Kubernetes CRDs and Operators to declaratively automate \u201cChannel/Thread\u201d management while offloading large-scale identity/auth and message processing to external systems (CollaborationPolicyService + MQ). This approach reduces Kubernetes control-plane dependency and delivers high scalability, paving the way for a \u201cDiscord-like\u201d system for multi-Agent communication. Future extensions (e.g., AI/LLM-based collaboration) can easily integrate into this architecture, maintaining a unified cloud-native operations model.</p>"},{"location":"entity-component-system/","title":"Overview","text":"<p>Lithops takes the entity-component-system (ECS) architecture from game development and scales it up to support millions of entities in a decentralized fashion.</p>"},{"location":"entity-component-system/components-management/","title":"Lithops-ECS Components Management","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#1-overall-approach","title":"1. Overall Approach","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Prepare the storage and network services for hosting package files and index files (e.g., an HTTP server).</li> <li>Create the private repository directory structure and use tools provided by <code>apk</code> to generate the index.</li> <li>Generate a signing key using <code>abuild-keygen</code>, <code>openssl</code>, or similar, and sign the generated index.</li> <li>On the Alpine client, add the private repository address and import the public signing key.</li> <li>Test and verify that the client can install packages from the private repository successfully.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#2-environment-preparation","title":"2. Environment Preparation","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Alpine Linux Version Selection </li> <li>Preferably use a newer Alpine version (e.g., Alpine 3.17/3.18) to obtain the latest features and security patches.</li> <li> <p>Ensure that the Alpine versions of the server and clients are the same or compatible to avoid compatibility issues (e.g., differences in dependency libraries).</p> </li> <li> <p>Basic Software Installation </p> </li> <li>Install <code>abuild</code>: for packaging, managing signing keys, and generating indexes. <pre><code>apk add abuild\n</code></pre></li> <li> <p>Install necessary tools and services, such as: <pre><code>apk add openssl bash tar nginx  # or httpd, mini_httpd, or any HTTP service\n</code></pre></p> </li> <li> <p>User, Permissions, and Environment Configuration </p> </li> <li>Create a dedicated user for packaging and managing the private repository (e.g., <code>alpinebuild</code>) to avoid additional risks associated with using root.</li> <li>Configure <code>abuild</code> for the user: <pre><code>abuild-keygen -i                     # Generate key and automatically install it in ~/.abuild/ directory\necho 'PACKAGER_PRIVKEY=\"$HOME/.abuild/&lt;yourkey&gt;.rsa\"' &gt;&gt; ~/.abuild/abuild.conf  \n</code></pre></li> <li>Ensure that <code>PACKAGER_PRIVKEY</code>, <code>PACKAGER</code>, <code>PACKAGER_EMAIL</code>, and other settings in <code>abuild.conf</code> are correctly configured.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#3-creating-the-private-repository-directory-structure","title":"3. Creating the Private Repository Directory Structure","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Repository Directory Specification </li> <li>Simplified example of the Alpine official repository structure:      <pre><code>/alpine/         # Root directory\n\u251c\u2500\u2500 v3.18/\n\u2502   \u251c\u2500\u2500 main/\n\u2502   \u251c\u2500\u2500 community/\n\u2502   \u2514\u2500\u2500 testing/\n\u2514\u2500\u2500 v3.17/ ...\n</code></pre></li> <li> <p>The private repository can set up a simplified structure based on actual needs. For instance, only keeping <code>main/</code>, or using a custom name like <code>private/</code>:      <pre><code>/myrepo/         # Root directory\n\u251c\u2500\u2500 x86_64/\n\u2502   \u2514\u2500\u2500 main/\n\u2502       \u251c\u2500\u2500 mypkg-1.0.0-r0.apk\n\u2502       \u251c\u2500\u2500 APKINDEX.tar.gz\n\u2502       \u2514\u2500\u2500 APKINDEX.tar.gz.sign\n\u2514\u2500\u2500 armv7/ ...   # Add additional architectures as needed\n</code></pre></p> </li> <li> <p>Recommended Directory Planning and Naming </p> </li> <li>Create the root directory of the private repository in /var/www/html, /srv, or another hidden network share path (this document assumes /var/www/myrepo/).</li> <li>Create corresponding subdirectories for each architecture (e.g., x86_64, aarch64) based on the required architecture.</li> <li>If there are multiple branches or channels, further subdivide within the architecture directory. Otherwise, use only the <code>main</code> directory to store packages.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#4-building-apk-packages-generating-index","title":"4. Building APK Packages &amp; Generating Index","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Building/Preparing APK Packages </li> <li>Use <code>abuild</code> to create custom packages or directly download and modify packages from the official repository before repackaging.</li> <li> <p>If only hosting existing APK files, simply place compliant .apk files into the corresponding directory.</p> </li> <li> <p>Generating the Index (APKINDEX.tar.gz) </p> </li> <li> <p>Execute the following in the directory where .apk files are placed: <pre><code>apk index -o APKINDEX.tar.gz *.apk  \n</code></pre>      Here, <code>*.apk</code> represents all the apk packages in the same directory, and the <code>apk index</code> command generates an index file based on the metadata of the APK packages.</p> </li> <li> <p>Signing the Index </p> </li> <li>Sign <code>APKINDEX.tar.gz</code> using the private key: <pre><code>abuild-sign APKINDEX.tar.gz\n</code></pre>      Alternatively, use <code>openssl</code> for signing, although using <code>abuild-sign</code> is recommended for compatibility and ease.</li> <li>This step will generate the <code>APKINDEX.tar.gz.sign</code> file in the same directory.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#5-configuring-and-starting-http-service","title":"5. Configuring and Starting HTTP Service","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Choosing and Installing HTTP Service </li> <li> <p>Example for <code>nginx</code> (can be replaced by <code>httpd</code>, <code>lighttpd</code>, <code>mini_httpd</code>, etc.): <pre><code>apk add nginx  \n</code></pre>      After installation, add a server block in <code>/etc/nginx/nginx.conf</code> or the appropriate configuration file, specifying the root directory as the location of the repository.</p> </li> <li> <p>Example:  <pre><code>server {\n  listen 80;\n  server_name myapkrepo.local;\n\n  root /var/www/myrepo/;\n  autoindex on;   # Enable or disable directory listing\n}  \n</code></pre></p> </li> <li> <p>Permissions and Security </p> </li> <li>Ensure the directory <code>/var/www/myrepo/</code> is readable by <code>nginx</code> (or other service users).</li> <li> <p>If external access is needed, apply access restrictions or use HTTPS, and configure appropriate firewall rules or VPN tunnels to protect internal resources.</p> </li> <li> <p>Starting the Service </p> </li> <li>Start using the command: <pre><code>rc-service nginx start  \n</code></pre></li> <li>Alternatively, use systemctl or supervisord for management.</li> <li>Test access by visiting, for example, <code>http://myapkrepo.local/x86_64/main/</code> in a web browser or command line to verify.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#6-configuring-the-client-for-private-repository","title":"6. Configuring the Client for Private Repository","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Importing the Signing Public Key </li> <li>Copy the <code>.pub</code> file generated by <code>abuild-keygen</code> to the client: <pre><code>/etc/apk/keys/&lt;YourKeyName&gt;.rsa.pub  \n</code></pre></li> <li>Alternatively, place the public key in <code>/usr/share/apk/keys/</code>.</li> <li> <p>Ensure the public key filename follows the official naming style, e.g., <code>hoid@myorg.rsa.pub</code>.</p> </li> <li> <p>Editing /etc/apk/repositories </p> </li> <li>Add an entry for the private repository in the target client's configuration: <pre><code>http://myapkrepo.local/x86_64/main  \n</code></pre></li> <li> <p>If using HTTPS, ensure the certificate is correctly installed and trusted.</p> </li> <li> <p>Refreshing and Testing Installation </p> </li> <li>Update and test installation: <pre><code>apk update  \napk search &lt;test-package-name&gt;  \napk add &lt;test-package-name&gt;  \n</code></pre></li> <li>If installation succeeds, the configuration is successful.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#7-best-practices-for-maintenance-and-upgrades","title":"7. Best Practices for Maintenance and Upgrades","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>Continuous Updates/Additions of APK </li> <li>Each time new or updated <code>.apk</code> files are added, the <code>apk index</code> and <code>abuild-sign</code> commands should be rerun to update the index file and signature.</li> <li> <p>For example, if a new <code>mypkg-1.0.1-r0.apk</code> is placed in the directory: <pre><code>rm APKINDEX.tar.gz  # Remove the old index\nrm APKINDEX.tar.gz.sign\napk index -o APKINDEX.tar.gz *.apk  \nabuild-sign APKINDEX.tar.gz  \n</code></pre></p> </li> <li> <p>Regular Key Rotation </p> </li> <li>Using the same key for extended periods poses security risks, so periodically change the private key and distribute the new public key to clients.</li> <li> <p>It is recommended to regenerate and publish new keys at least annually or biannually, keeping the old keys for a while to maintain compatibility with clients that have not been updated.</p> </li> <li> <p>Version Management </p> </li> <li>If different Alpine versions need to provide adapted packages, organize the root directory of the repository by version or channel (e.g., <code>main</code>, <code>testing</code>, <code>stable</code>, <code>edge</code>, etc.).</li> <li> <p>Maintain a clear and concise directory structure, timely removing outdated packages to avoid uncontrolled growth of the repository size.</p> </li> <li> <p>Backup and Disaster Recovery </p> </li> <li>Backup the private keys, repository directory structure, and all APK files to offline or secure locations.</li> <li>Regularly perform incremental backups using tools like <code>rsync</code>, <code>tar</code>, or others.</li> <li> <p>When recovery is needed, simply restore files and signatures to the original directory and enable the service.</p> </li> <li> <p>Audit and Monitoring </p> </li> <li>Configure the web server or local system logs to monitor access to the repository appropriately.</li> <li>Regularly review access logs and error logs to detect potential malicious activities or sync issues.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#8-common-issues-and-recommendations","title":"8. Common Issues and Recommendations","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p> <ol> <li>APKINDEX.tar.gz Signature Failure or Unknown signer </li> <li>Ensure the client has imported the matching public key and that the public key path and name are correct.</li> <li> <p>Check that the public key and private key versions correspond.</p> </li> <li> <p>Client reports \"404 Not Found\" or other network errors </p> </li> <li>Verify that the repository directory and root directory in the HTTP server configuration match the expected URL path.</li> <li> <p>Confirm that certificates and firewall settings are correct.</p> </li> <li> <p>Package Installation Dependency Conflicts </p> </li> <li> <p>Pay attention to compatibility between Alpine versions, ensuring that the packages in the private repository are consistent with system dependencies or can revert to compatible versions.</p> </li> <li> <p>Need to Enable HTTPS </p> </li> <li>Use an internally issued CA certificate and apply it to servers such as <code>nginx</code>.</li> <li>Ensure clients trust the corresponding CA.</li> </ol> <p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501</p>"},{"location":"entity-component-system/components-management/#conclusion","title":"Conclusion","text":"<p>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 By following the steps outlined above, you can deploy a relatively secure and maintainable private APK package management repository in an Alpine Linux environment. Key points include: - Clearly plan your directory structure and integrate with HTTP services; - Properly generate and distribute signing and public keys to ensure package integrity and trustworthiness; - Import public keys synchronously when configuring clients for private sources; - Timely update package indexes and sign them; - Continuously rotate keys, perform backups, and conduct access audits to enhance overall security and reliability.</p> <p>This solution can be applied in both internal network environments and securely used in limited external environments, meeting the needs of most Alpine Linux scenarios for building, distributing, and managing privatized software packages.</p>"},{"location":"entity-component-system/implementation-architecture-choices/","title":"Overview of Distributed ECS Implementation Approaches","text":"<p>Note</p> <p>This is just a tentative design.</p> <p>This document discusses a number of approaches for implementing large-scale, distributed and decentralized entity-component systems.</p> <p>Currently, we take the third approach, i.e., runtime component injection.</p>"},{"location":"entity-component-system/implementation-architecture-choices/#special-challenges-with-distributed-ecs","title":"Special Challenges with Distributed ECS","text":"<p>Since Lithops implements distributed, large scale entity-component system, there are some unique challenges that do not arise in general game development.</p>"},{"location":"entity-component-system/implementation-architecture-choices/#error-handling","title":"Error Handling","text":"<p>Lithops ECS is designed to be high-available and fault-tolerant. bugs or null reference errors on an actor/component must not crash the entire system.</p>"},{"location":"entity-component-system/implementation-architecture-choices/#concurrency","title":"Concurrency","text":"<p>Concurrency is an issue rarely encountered in game development, because mainstream game engines are generally single-threaded (known as the game thread). Despite the performance issues, this is a deliberate design choice that eliminates concurrency-specific concerns for artists and game developers, a population with generally no strong background in software development and system programming.</p> <p>However, large-scale distributed ECS systems are inherently concurrent and asynchronous, and it is unrealistic to employ a single-threaded approach because the performance degradation would be unacceptable.</p>"},{"location":"entity-component-system/implementation-architecture-choices/#architecture-choices","title":"Architecture Choices","text":"<p>There are several schemes to implement the Entity-Component-System (ECS) architecture.</p>"},{"location":"entity-component-system/implementation-architecture-choices/#one-container-per-actor","title":"One Container Per Actor","text":"<p>This is the easiest scheme to think of. In this scheme, each actor is associated with a single container, and all components in that actor are isolated in that container.</p> <p>Pros:</p> <ul> <li>Each actor with its components is isolated, and failure within one actor does not affect the others.</li> <li>There is minimal communication cost between multiple components on a single actor.</li> </ul> <p>Cons:</p> <ul> <li>Even though the number of components is limited, the number of possible combinations, and hence the number of actor types, can be potentially large. If we were to create an image for each actor with a different set of components, the number of docker images would blow up.</li> <li>Does not allow adding or removing components at runtime.</li> <li>Cannot handle very large actors because each actor must fit on one node.</li> </ul>"},{"location":"entity-component-system/implementation-architecture-choices/#one-service-per-component","title":"One Service Per Component","text":"<p>In this scheme, each type of component is implemented as a service which automatically load-balances across multiple nodes as the number of actors using this component grows. All actors using the same type of component connects to the same service endpoint.</p>"},{"location":"entity-component-system/implementation-architecture-choices/#general-architecture","title":"General Architecture","text":"<p>Physically, each type of component is exposed as a service which may be deployed over one or multiple nodes. The idea is, component services are guaranteed to be always available, and scales automatically with the number of actors using them.</p> <p>For example, consider a multi-agent system:</p> <pre><code>graph TD\n    A1(Actor 1) --&gt; C11(Component 1)\n    A1 --&gt; C12(Component 2)\n    A2(Actor 2) --&gt; C21(Component 1)</code></pre> <p>The implementation might look like:</p> <pre><code>graph TD\n    A1(Actor 1) --&gt; C1\n    A2(Actor 2) --&gt; C1\n    A1 --&gt; C2\n    C1(Component 1 Service)\n    C2(Component 2 Service)\n    C1 --&gt; N1(Node 1)\n    C1 --&gt; N2(Node 2)\n    C2 --&gt; N2</code></pre>"},{"location":"entity-component-system/implementation-architecture-choices/#component-service-implementation","title":"Component Service Implementation","text":"<p>To ensure isolation across different component instances, each instance of a component is encapsulated in its own process.</p> <p>Pros:</p> <ul> <li>Scales to large number of actors with different combinations of components.</li> <li>Allows dynamically adding and removing components   after an actor is spawned (like in game engines).</li> <li>Scales well in situations where there is a single actor so large it cannot fit on one machine, as components in an actor are distributed across multiple services and nodes in nature.</li> </ul> <p>Cons:</p> <ul> <li>It can be hard to ensure isolation between   different instances of the same component type   attached to different actors,   especially when those instances are deployed on the same node.</li> <li>Each inter-component event requires a round-trip over the cluster network,   even for the components on the same actor.</li> </ul>"},{"location":"entity-component-system/implementation-architecture-choices/#runtime-component-injection","title":"Runtime Component Injection","text":"<p>This scheme is similar to \"One Container Per Actor\", in that each actor gets its own container. The difference is that instead of creating an image for each different combination of components, there is only one image providing the basic functionalities like event passing. When an actor is spawn, a container is created, then the components are injected into the container.</p> <p>The critical design choice with this architecture is how to package the runtime code for each component. Apparently, we want something more lightweight than a container since the components are already running in a container. May look into existing sandboxing solutions like snap and AppImage.</p> <p>In general, the means of component packaging/virtualization should:</p> <ol> <li>Be lightweight;</li> <li>Ensure isolation between different components on the same actor.</li> </ol> <p>Pros:</p> <ul> <li>Ensures isolation between different actors.</li> <li>Keeps the number of packages at a minimum even when there are a large number of actors with different combinations of components.</li> <li>Allows dynamically adding and removing components after an actor is spawned (like in game engines).</li> </ul> <p>Cons:</p> <ul> <li>The process of component injection can introduce unexpected bugs. For example, if two components use the same temporary directory in the host container, they may interfere with each other and cause unwanted behavior even if they have no bugs on their own.</li> <li>Cannot handle very large actors because each actor must fit on one node.</li> </ul>"},{"location":"entity-component-system/implementation-architecture-choices/#runtime-component-injection_1","title":"Runtime Component Injection","text":"<p>Currently, we employ the runtime component injection approach for implementing the ECS architecture.</p> <p>The design ideas are:</p> <ul> <li>Components may be buggy so there needs to be some sandboxing for each component.</li> <li>Component sandboxing should incur minimal overhead since we're already inside a container.</li> <li>Components should be self-contained to avoid dependency and environment configuration issues.</li> </ul> <p>Specifically:</p> <ul> <li>Use AppImage to package each component into a self-contained binary.</li> <li>Use BubbleWrap to sandbox each component AppImage and provide a safe, ephemeral mount point for it to write to, similar to a Docker volume (expect that it does not persist). Restrict AppImages from accessing the host filesystem to avoid multiple components sharing the same file system and interfering with each other.</li> </ul>"},{"location":"entity-component-system/implementation-architecture/","title":"Lithops Distributed ECS Implementation Architecture","text":"<p>This document discusses the high-level architecture that Lithops employs to implement large scale, distributed and decentralized entity-component systems.</p>"},{"location":"entity-component-system/implementation-architecture/#architecture-overview","title":"Architecture Overview","text":"<p>Lithops employs the runtime component injection architecture for implementing distributed ECS and adds an abstraction named \"service\" for implementing API services that need load-balancing, such as image generation.</p> <p>There are four core concepts in the ECS architecture.</p>"},{"location":"entity-component-system/implementation-architecture/#actor","title":"Actor","text":"<p>Each actor with all its components runs as a container. An actor is assumed to be relatively lightweight and can fit on a single machine.</p>"},{"location":"entity-component-system/implementation-architecture/#component","title":"Component","text":"<p>Each component runs as a self-contained, sandboxed package inside the actor container. When an actor is spawned, the actor container is created, then the component packages are pulled and run.</p>"},{"location":"entity-component-system/implementation-architecture/#service","title":"Service","text":"<p>A service is a load-balanced API service endpoint providing stateless, potentially heavily-depended API services, such as text and image generation.</p>"},{"location":"entity-component-system/implementation-architecture/#core-functionality-service","title":"Core Functionality Service","text":"<p>This is a core functionality service endpoint (deployed and load-balanced automatically) that all actors/components use to access Lithops ECS core functionalities.</p> <p>All communications, event passing and API calls are proxied through this service.</p>"},{"location":"entity-component-system/implementation-architecture/#actor-api","title":"Actor API","text":"<p>The host image refers to the base image of the actor container. This does not include any components but must provide syscall-like APIs that the components use to implement their functionalities.</p> <p>For the MVP, we provide a minimal set of APIs that are used the most frequently in a well-structured game project:</p> <ul> <li>Get component by class (gets the first component of the given type);</li> <li>Find component by class and tag.</li> </ul> <p>For reference, a tag is a semantic string associated with either a component or an actor. Each component or actor can have multiple tags. In game development, a component use tags to find other components it depends on.</p>"},{"location":"entity-component-system/implementation-architecture/#component-sdk-api","title":"Component SDK API","text":"<p>Component SDK API refers to the APIs that component code uses to access the syscall-like entity-component system core functionalities.</p> <p>This includes:</p> <ul> <li>Sending and receiving events to/from other components, either on the same or different actors.</li> <li>Calling exposed APIs on other components/services.</li> </ul> <p>In Lithops, we organize such APIs in an object-oriented manner similar to game engines. Specifically:</p> <ul> <li>Component code can get handles to actors, components or services.</li> <li>These handles expose APIs such as sending events, binding event dispatchers and calling APIs (similar to calling public functions on other actors/components in game engines).</li> <li>These handles automatically handle the cases where actor/components fail and restart.</li> </ul>"},{"location":"entity-component-system/implementation-architecture/#messaging-api-calls","title":"Messaging &amp; API Calls","text":"<p>Actors and components may use the core service to get handles, but once that handle is acquired, it accesses the handle directly if possible and API calls are not proxied through the core service.</p> <p>Such a calling mechanism have different semantic implications in different scenarios:</p> <ul> <li>In case of calling a service: Operation guaranteed to success, since the service is inherently load-balanced and distributed.</li> <li>In case of calling a function on a component: Operation may fail or timeout, since the component may be invalid (e.g., null reference or pending kill).</li> <li>In case of broadcasting an event: Some of the listeners may be invalid and may not receive the event, but the semantics of event broadcast is the same with that in game engines, i.e., the event broadcaster does not care about who received the event or not.</li> </ul>"},{"location":"entity-component-system/logical-abstraction/","title":"Logical Abstraction","text":"<p>Lithops employs an entity-component-system (ECS) style architecture.</p> <p>In this architecture, everything in a multi-agent system is abstracted as an actor. This includes agents capable of critical thinking, frontend that interacts with the user, and even API services.</p> <p>An actor on its own does not do anything useful; its behavior is defined by the components attached to it.</p> <p>A component is a reusable piece of logic that adds a certain behavior to an actor.</p>"},{"location":"entity-component-system/logical-abstraction/#communication","title":"Communication","text":"<p>Actors and components communicate through events. Components may expose event dispatchers for other components from either the same or another actor to bind to. Of course, API calls are also supported; a component can call an exposed API from other components to process data or to invoke certain behavior.</p>"},{"location":"entity-component-system/logical-abstraction/#actor-discovery","title":"Actor Discovery","text":"<p>Actor discovery refers to how an actor finds other actors it needs to reference. For finding \"global actors\" such as API services and user interface component, we provide a tagging mechanism similar to those find in Unity and Unreal, where:</p> <ul> <li>Each actor can have a bunch of tags.</li> <li>There is a system-wide service for finding actor/actors with a specific tag.</li> </ul>"},{"location":"entity-component-system/logical-abstraction/#actor-virtualization","title":"Actor Virtualization","text":"<p>Actors are virtualized and automatically restarted/repaired on any non-intentional failures such as network disconnection or machine failures. From the user's perspective, actors are always alive and available unless intentionally destroyed.</p>"},{"location":"entity-component-system/logical-abstraction/#examples","title":"Examples","text":"<p>For a better understanding of the ECS architecture, let's look at some examples. Consider a simple multi-agent system that develops software from specification provided by the user. This system consists of the following actors:</p> <ul> <li>A frontend for interacting with the user.   Components:<ul> <li>A \"UserSoftwareSpecInput\" component that exposes an event dispatcher   which fires whenever the user submits a new software development request.</li> <li>A \"ReportOnDevComplete\" component   that reports to the user when a   software development goal completion event   (exposed by the LLMGoalFinisher component)   is fired.</li> </ul> </li> <li>A software developer agent for building software.   Components:<ul> <li>An \"LLMGoalFinisher\" component representing the agent's brain.   This component takes a goal, produces a plan and executes it.   During goal execution, it may call other tools.   This component exposes an event dispatcher to be fired   when the development of a software is complete.</li> <li>A \"ForwardGoal\" component that sets the goal of LLMGoalFinisher component   whenever the user inputs a software development request.</li> </ul> </li> <li>A compiler service that takes the source code and outputs the compiled binary.   Components:<ul> <li>A \"CompilerService\" component that exposes a software compilation API.</li> </ul> </li> </ul>"},{"location":"general-design/","title":"Lithops General Design","text":"<p>This document outlines the general design of Lithops.</p>"},{"location":"general-design/design-philosophy/","title":"Design Philosophy","text":"<p>Lithops is designed around a set of ideas and goals: robustness &amp; decentralized control, separation of logical/physical construct and flexibility.</p>"},{"location":"general-design/design-philosophy/#robustness-decentralization","title":"Robustness &amp; Decentralization","text":"<p>Lithops deploys a large number of self-autonomous agents over a cluster. There is no centralized control and the failure of one agent has minimal impact over the others.</p>"},{"location":"general-design/design-philosophy/#separation-of-logicalphysical-construct","title":"Separation of Logical/Physical Construct","text":"<p>In Lithops, the logical abstraction of a multi-agent system and how it functions physically are decoupled.</p>"},{"location":"general-design/design-philosophy/#flexibility","title":"Flexibility","text":"<p>At its core, Lithops tries to introduce minimal inductive bias over how agents should be designed and how they behave.</p> <p>Rather than a monolithic framework, Lithops is a set of building blocks that can be composed to create a wide range of multi-agent systems. Some of these building blocks may have assumptions of a certain aspect of agents, and they may have dependency on other building blocks. These building blocks may be considered subsystems or micro-frameworks; they interact with each other according to protocols, a concept similar to trait in Rust.</p>"}]}